
# ğŸ‘ï¸â€ğŸ—¨ï¸ Semicolon â€” *Where syntax meets Sight*
An assistive device built on **ESP32-CAM + TF-Luna LiDAR + HC-SR04**, running an **Edge Impulse** model for on-device currency detection, with haptics and buzzer feedback.

<p align="center">
  <img src="assets/hero.jpg" width="80%" alt="Device hero image"/>
</p>

<div align="center">

![Build](https://img.shields.io/badge/build-passing-brightgreen)
![Platform](https://img.shields.io/badge/platform-ESP32--CAM-blue)
![Lang](https://img.shields.io/badge/lang-C%2FC%2B%2B-orange)
![License](https://img.shields.io/badge/license-MIT-lightgrey)

</div>

---

## âœ¨ Features
- **Navigation:** LiDAR primary + ultrasonic backup â†’ vibration intensity scales with distance.  
- **Currency detection:** Edge Impulse model runs fully on ESP32-CAM.  
- **Modes:** Button toggles NAV â†” CURRENCY; long-press = MUTE.  
- **Camera server:** Built-in web UI for live stream and capture.  

---

## ğŸ“¸ Images to upload
Upload these files to `assets/` in the repo root:

- `assets/hero.jpg` â†’ Hero banner/device render  
- `assets/build.jpg` â†’ Breadboard build photo  
- `assets/wiring.png` â†’ Wiring diagram/schematic  
- `assets/webui.png` â†’ Screenshot of web UI  
- `assets/coverage.png` â†’ LiDAR + ultrasonic coverage diagram  
- `assets/currency-demo.gif` â†’ Short demo (currency detection)  

---

## ğŸ—‚ï¸ Repo layout

.
â”œâ”€ firmware/
â”‚  â”œâ”€ src/
â”‚  â”‚  â”œâ”€ main.cpp
â”‚  â”‚  â”œâ”€ drivers/ (tf_luna., ultrasonic., haptics., audio., button., camera.)
â”‚  â”‚  â””â”€ inference/edge_impulse/  # drop exported EI library here
â”‚  â””â”€ platformio.ini
â”œâ”€ mechanical/ (enclosure.stl, faceplate.stl)
â”œâ”€ assets/ (images listed above)
â””â”€ README.md

---

## ğŸ› ï¸ Hardware
- **ESP32-CAM (AI-Thinker)** with **PSRAM enabled**  
- **TF-Luna LiDAR** (UART)  
- **HC-SR04 Ultrasonic** (TRIG/ECHO; ECHO via 5Vâ†’3.3V divider)  
- **Vibration motor** (ERM) + NPN transistor (2N2222) + 1 kÎ© resistor + diode  
- **Active buzzer** (or I2S amp + speaker)  
- **3.7 V Li-ion/LiPo** + TP4056 charger (with protection) + 5 V boost  
- **Momentary push button**  
- *(Optional)* OLED IÂ²C screen  

---

## ğŸ”Œ Wiring (example)
<p align="center">
  <img src="assets/wiring.png" width="80%" alt="Wiring diagram"/>
</p>

| Signal | ESP32-CAM Pin | Notes |
|---|---|---|
| TF-Luna TX/RX | GPIO16 (RX2) / GPIO17 (TX2) | `Serial2` |
| HC-SR04 TRIG/ECHO | GPIO14 / GPIO15 | ECHO via divider |
| Vibration motor | GPIO12 â†’ transistor | base 1kÎ©, diode across motor |
| Buzzer | GPIO13 | Active buzzer |
| Button | GPIO2 | `INPUT_PULLUP` |
| Power | 5 V / GND | From boost module; common GND |

---

## âš™ï¸ Build & Flash

**Arduino IDE**
1. Install ESP32 board support.  
2. Board: **AI Thinker ESP32-CAM**; PSRAM: **Enabled**; Partition: **Huge APP** or `partitions.csv`.  
3. Upload `esp32_c.ino` (or `main.cpp` converted to `.ino`).  
4. Serial Monitor @ 115200 â†’ get device IP.  

**PlatformIO (VS Code)**  
```ini
[env:esp32cam]
platform = espressif32
board = esp32cam
framework = arduino
board_build.partitions = partitions.csv
build_flags =
  -DEI_CLASSIFIER_TFLITE_ENABLE_ESP_NN=1
  -DEI_CLASSIFIER_ALLOCATION_STATIC=1
monitor_speed = 115200

cd firmware
pio run -t upload
pio device monitor


â¸»

ğŸ§  Edge Impulse (currency)
	1.	In Edge Impulse â†’ Deploy â†’ Arduino Library (EON + int8).
	2.	Place library in firmware/src/inference/edge_impulse/.
	3.	Use grayscale, QQVGA/QVGA frames to save RAM.
	4.	Inference result â†’ beep patterns.

â¸»

ğŸŒ Web Endpoints
	â€¢	/ â†’ control page
	â€¢	/stream â†’ MJPEG stream
	â€¢	/capture â†’ single JPEG
	â€¢	/status â†’ JSON camera status
	â€¢	/control?var=<name>&val=<int> â†’ set camera param

<p align="center">
  <img src="assets/webui.png" width="80%" alt="Web UI"/>
</p>



â¸»

ğŸ§­ Modes
	â€¢	NAV: haptics scale with distance.
	â€¢	CURRENCY: run inference; beep per denomination.
	â€¢	MUTE: hold button ~1.5s.

â¸»

ğŸ§ª Quick test
	1.	Power up device.
	2.	Visit http://<esp32-ip>/capture â†’ see still image.
	3.	Visit http://<esp32-ip>/stream â†’ live video works.
	4.	Press button to switch NAV/CURRENCY; listen for feedback.

â¸»

ğŸ§¯ Troubleshooting
	â€¢	Camera init fail / resets: Power sag â†’ use boost module >700 mA; disable Wi-Fi if unused:

#include <WiFi.h>
void setup(){ WiFi.mode(WIFI_OFF); btStop(); }


	â€¢	PSRAM allocation error: Lower frame size; use grayscale; ensure Huge APP/custom partition.
	â€¢	Ultrasonic noisy: Keep wires short; use voltage divider; common ground.

â¸»

ğŸ—ºï¸ Roadmap
	â€¢	Tie EI inference tightly to camera ring buffer.
	â€¢	I2S amp + mini speaker for clearer voice prompts.
	â€¢	OLED status screen.
	â€¢	Perfboard/PCB + 3D-printed enclosure.

â¸»

ğŸ™Œ Credits
	â€¢	Edge Impulse for TinyML tooling.
	â€¢	ESP32 + open hardware communities.

â¸»

ğŸ“„ License

MIT

Do you want me to also give you the **GitHub commands** (from `git init` â†’ `commit` â†’ `push`) so you can upload this `README.md` file into a fresh repo directly?
